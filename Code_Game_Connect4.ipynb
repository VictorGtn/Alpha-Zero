{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Reinforcement Learning : Code Connect 4 Game \n","\n","As part of this project, we implemented a Connect 4 game that operates with a simple version of the AlphaZero algorithm. To do this we followed freeCodeCamp tutorial, originally intented for the TicTacToe game, and which we adapted for Connect 4 game. \n","\n","Tutorial : https://www.youtube.com/watch?v=wuSQpLinRB4\n","\n","Members of the group : AMEDEE Romain, GERTNER Victor, MERRHEIM Ma√Øssane"]},{"cell_type":"code","execution_count":39,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-16T07:32:45.797391Z","iopub.status.busy":"2024-02-16T07:32:45.797016Z","iopub.status.idle":"2024-02-16T07:32:46.768306Z","shell.execute_reply":"2024-02-16T07:32:46.767376Z","shell.execute_reply.started":"2024-02-16T07:32:45.797363Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:05.816027Z","iopub.status.busy":"2024-02-16T07:33:05.815024Z","iopub.status.idle":"2024-02-16T07:33:05.823398Z","shell.execute_reply":"2024-02-16T07:33:05.822511Z","shell.execute_reply.started":"2024-02-16T07:33:05.815988Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fe2303ed290>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math \n","import numpy as np \n","from scipy.signal import convolve2d\n","from tqdm.notebook import trange\n","\n","torch.manual_seed(0) #reproduceable results"]},{"cell_type":"markdown","metadata":{},"source":["Firstly, we first implemented a class called Connect4, where we established the basic rules of the game, including functions like get_legal_actions() and check_win() functions.\n","To detect if 4 pawns were aligned consecutively, whether it is in diagonally or horizontally or vertically, we used a kernel of size 4 and convolve2d layers.\n"]},{"cell_type":"markdown","metadata":{},"source":["# Connect 4 Game : class Connect4"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:20.988363Z","iopub.status.busy":"2024-02-16T07:33:20.988020Z","iopub.status.idle":"2024-02-16T07:33:21.003824Z","shell.execute_reply":"2024-02-16T07:33:21.002897Z","shell.execute_reply.started":"2024-02-16T07:33:20.988336Z"},"trusted":true},"outputs":[],"source":["class Connect4: \n","\n","    def __init__(self): \n","        self.row_count = 6\n","        self.column_count = 7\n","        self.action_size = self.column_count\n","\n","    def get_initial_state(self): \n","        return np.zeros((self.row_count, self.column_count))\n","    \n","    def get_next_state(self, state, action, player):\n","        #action integer between 0 and 8 \n","        \"\"\"row = action // self.column_count\n","        column = action % self.column_count\n","        state[row,column] = player\n","        return state\"\"\"\n","\n","        column = action\n","        for row in range(self.row_count-1, -1, -1):\n","            if state[row, column] == 0:\n","                state[row, column] = player\n","                break\n","        return state \n","\n","    def get_legal_actions(self, state): \n","        return np.array([state[0, col] == 0 for col in range(self.column_count)])\n","\n","\n","    def check_win(self, state, action): \n","        if action == None : \n","            return False \n","            \n","        kernel = np.ones((1, 4), dtype=int)\n","        \n","        # Horizontal and vertical checks\n","        horizontal_check = convolve2d(state, kernel, mode='valid')\n","        vertical_check = convolve2d(state, kernel.T, mode='valid')\n","\n","        # Diagonal checks\n","        diagonal_kernel = np.eye(4, dtype=int)\n","        main_diagonal_check = convolve2d(state, diagonal_kernel, mode='valid')\n","        anti_diagonal_check = convolve2d(state, np.fliplr(diagonal_kernel), mode='valid')\n","        \n","        # Check for winner\n","        if any(cond.any() for cond in [horizontal_check == 4, vertical_check == 4, main_diagonal_check == 4, anti_diagonal_check == 4]):\n","            return 1\n","        elif any(cond.any() for cond in [horizontal_check == -4, vertical_check == -4, main_diagonal_check == -4, anti_diagonal_check == -4]):\n","            return -1\n","\n","        # No winner\n","        return 0  \n","\n","    def get_value_and_terminated(self, state, action): \n","        if self.check_win(state, action) : \n","            # value = 1 , terminated = True\n","            return 1, True\n","        if np.sum(self.get_legal_actions(state)) == 0: \n","            #pas de gagnant value = 1, terminated = True \n","            return 0, True \n","        return 0, False\n","    \n","    def get_opponent(self, player): \n","        return -player\n","\n","    def get_opponent_value(self, value): \n","        return -value\n","\n","    def change_perspective(self, state, player): \n","        return state * player \n","    \n","    def get_encoded_state(self, state): \n","        encoded_state = np.stack(\n","            (state == -1, state == 0, state == 1)\n","        ).astype(np.float32)\n","        return encoded_state"]},{"cell_type":"markdown","metadata":{},"source":["# Neural Networks : ResBlock and ResNet classes"]},{"cell_type":"markdown","metadata":{},"source":["We then implemented two neural networks : Resblock and the Resnet classes. These neural networks architectures enable to train deep neural networks and often used for image recognition. In our implementation of the AlphaZero network, Resnet takes in\n","input a matrix that represents the board state and return to outputs :\n","- the value of the position of the pawn : either 1 if player 1 wins or -1 if player 1 looses.\n","- a policy,that represents a vector a prior probabilities for each next legal move.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:28.215412Z","iopub.status.busy":"2024-02-16T07:33:28.214476Z","iopub.status.idle":"2024-02-16T07:33:28.225052Z","shell.execute_reply":"2024-02-16T07:33:28.224017Z","shell.execute_reply.started":"2024-02-16T07:33:28.215371Z"},"trusted":true},"outputs":[],"source":["class ResBlock(nn.Module):\n","    def __init__(self, num_hidden): \n","        super().__init__()\n","        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size = 3, padding = 1)\n","        self.bn1 = nn.BatchNorm2d(num_hidden)\n","        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size = 3, padding = 1)\n","        self.bn2 = nn.BatchNorm2d(num_hidden)\n","\n","    def forward(self, x): \n","        residual = x\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = self.bn2(self.conv2(x))\n","        x += residual \n","        x + F.relu(x)\n","        return x"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:34.469004Z","iopub.status.busy":"2024-02-16T07:33:34.468309Z","iopub.status.idle":"2024-02-16T07:33:34.478166Z","shell.execute_reply":"2024-02-16T07:33:34.477255Z","shell.execute_reply.started":"2024-02-16T07:33:34.468972Z"},"trusted":true},"outputs":[],"source":["class ResNet(nn.Module): \n","    def __init__(self, game, num_resBlocks, num_hidden): \n","        super().__init__()\n","        self.startBlock = nn.Sequential(\n","            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(num_hidden), \n","            nn.ReLU()\n","            )\n","        self.backBone = nn.ModuleList(\n","            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n","        )\n","        self.policyHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 32, kernel_size = 3, padding=1),\n","            nn.BatchNorm2d(32), \n","            nn.ReLU(),\n","            nn.Flatten(), \n","            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n","        )\n","        self.valueHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 3,  kernel_size=3, padding=1), \n","            nn.BatchNorm2d(3),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(3 * game.row_count * game.column_count, 1), \n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x): \n","        x = self.startBlock(x)\n","        for resBlock in self.backBone:\n","            x = resBlock(x)\n","        policy = self.policyHead(x)\n","        value = self.valueHead(x)\n","        return policy, value"]},{"cell_type":"markdown","metadata":{},"source":["# Standard MCTS (Monte Carlo Tree Search) Algorithm"]},{"cell_type":"markdown","metadata":{},"source":["In order to run a MCTS algorithm (Monte-Carlo Tree Search) algorithm, we first needed to implement a class called \\texttt{Node}, that implement the 3 main steps of the MCTS algorithm for the AlphaZero model : \n","- Selection of a node : select()\n","- Expansion of a node : expand()\n","- Backpropagation :backpropagate()\n","\n","\n","The function get_ucb() enables to compute the ucb score of a node following this formula : \n","$$ v_{i} + C \\times \\frac{\\sqrt{\\ln N}}{n_i} $$\n","\n","\n","with $v_i$ the estimated value of the node $i$,  $n_i$ is the number of the times the node has been visited and  $N$ is the total number of times that its parent has been visited.\n","\n","However, for the first step, we decided to implement a 'standard' MCTS class that would \"simulate\" playouts instead of learning them, so that we can compare the different generated policies between the standard MCTS algorithm, and the MCTS algorithm adapted to AlphaZero. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math \n","\n","class Node : \n","    def __init__(self, game, args, state, parent=None, action_taken=None): \n","        self.game = game \n","        self. args = args \n","        self.state = state \n","        self.parent = parent \n","        self.action_taken = action_taken \n","\n","        self.children = []\n","        self.expandable_moves = game.get_legal_actions(state)\n","\n","        self.visit_count = 0 \n","        self.value_sum = 0\n","\n","    def is_fully_expanded(self):\n","        return np.sum(self.expandable_moves) == 0 and len(self.children) > 0\n","\n","    def select(self): \n","        best_child = None \n","        best_ucb = -np.inf \n","        for child in self.children : \n","            ucb = self.get_ucb(child)\n","            if ucb > best_ucb: \n","                best_child = child\n","                best_ucb = ucb \n","\n","            return best_child\n","    \n","    def get_ucb(self, child): \n","        q_value = 1 - (child.value_sum / child.visit_count) + 1 / 2 \n","        #the child and the parent are different players -> put our opponent in a bad move \n","        # so we prefer a bad position with a bad q_value for the opponent \n","        return q_value + self.args['C'] * math.sqrt(math.log(self.visit_count)/child.visit_count)\n","\n","    def expand(self): \n","        indices = np.where(self.expandable_moves == 1)[0]  # Obtenir les indices unidimensionnels\n","        action = np.random.choice(indices)\n","        #action = np.random.choice([np.where(self.expandable_moves == 1)[0]])\n","        #make this move no longer exapndable \n","        self.expandable_moves[action] = 0 \n","\n","        child_state = self.state.copy()\n","        child_state = self.game.get_next_state(child_state, action, 1)\n","        #never change the player change the state of the child and change the perception \n","        child_state = self.game.change_perspective(child_state, player=-1)\n","\n","        child = Node(self.game, self.args, child_state, self, action)\n","        # we are the parent \n","        self.children.append(child)\n","        return child\n","\n","    def simulate(self): \n","        value, is_terminal = self.game.get_value_and_terminated(self.state, self.action_taken)\n","        value = self.game.get_opponent_value(value)\n","\n","        if is_terminal : \n","            return value \n","        rollout_state = self.state.copy()\n","        rollout_player = 1\n","        while True : \n","            legal_actions = self.game.get_legal_actions(rollout_state)\n","            action = np.random.choice(np.where(legal_actions == 1)[0])\n","            rollout_state = self.game.get_next_state(rollout_state,action,rollout_player)\n","            value, is_terminal = self.game.get_value_and_terminated(rollout_state, action)\n","            if is_terminal: \n","                if rollout_player == -1: \n","                    value = self.game.get_opponent_value(value)\n","                return value \n","            rollout_player = self.game.get_opponent(rollout_player)\n","            \n","    def backpropagate(self, value): \n","        self.value_sum += value \n","        self.visit_count +=1 \n","        value = self.game.get_opponent_value(value)\n","        if self.parent is not None: \n","            self.parent.backpropagate(value)\n","\n","class MCTS: \n","    def __init__(self, game, args): \n","        self.game = game \n","        self.args = args \n","    \n","    def search(self, state): \n","        #define root node \n","        root = Node(self.game, self.args, state)\n","        for search in range(self.args['num_searches']): \n","            node = root\n","            # selection \n","            while node.is_fully_expanded():\n","                node = node.select()\n","                #chcek if the node is a terminated one \n","                #action taken -> action of the opponent\n","            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n","            value = self.game.get_opponent_value(value)\n","\n","            # expansion \n","            if not is_terminal: \n","                node = node.expand()\n","                 \n","                # simulation\n","                value = node.simulate() \n","            # backpropagation \n","            node.backpropagate(value)\n","\n","        # return visit_counts \n","        action_probs = np.zeros(self.game.action_size)\n","        for child in root.children: \n","            action_probs[child.action_taken] = child.visit_count \n","        action_probs /= np.sum(action_probs)\n","        return action_probs"]},{"cell_type":"markdown","metadata":{},"source":["## Simulation and test "]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:40.011658Z","iopub.status.busy":"2024-02-16T07:33:40.011006Z","iopub.status.idle":"2024-02-16T07:33:40.374706Z","shell.execute_reply":"2024-02-16T07:33:40.373787Z","shell.execute_reply.started":"2024-02-16T07:33:40.011626Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1.]]\n","\n"," [[1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 0. 1. 1. 1. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0.]]]\n","value : 0.04013870283961296 policy : [0.14335124 0.18187433 0.08020195 0.12876034 0.17010544 0.10559373\n"," 0.19011292]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","connect4 = Connect4()\n","\n","state = connect4.get_initial_state()\n","state = connect4.get_next_state(state, 2, 1)\n","state = connect4.get_next_state(state, 6, -1)\n","\n","encoded_state = connect4.get_encoded_state(state)\n","print(encoded_state)\n","\n","tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n","\n","model = ResNet(connect4, 4, 64)\n","policy, value = model(tensor_state)\n","value = value.item()\n","policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","\n","print(\"value :\", value, \"policy :\", policy)\n","\n","plt.bar(range(connect4.action_size), policy)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# MCTS (adapted to AlphaZero, without the simluation step)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:54.941361Z","iopub.status.busy":"2024-02-16T07:33:54.940759Z","iopub.status.idle":"2024-02-16T07:33:54.951618Z","shell.execute_reply":"2024-02-16T07:33:54.950708Z","shell.execute_reply.started":"2024-02-16T07:33:54.941331Z"},"trusted":true},"outputs":[],"source":["class MCTS: \n","    def __init__(self, game, args, model): \n","        self.game = game \n","        self.args = args \n","        self.model = model \n","    \n","    @torch.no_grad() # don't want to use policy and value for training\n","    #faster\n","    def search(self, state): \n","        #define root node \n","        root = Node(self.game, self.args, state)\n","        for search in range(self.args['num_searches']): \n","            node = root\n","            # selection \n","            while node.is_fully_expanded():\n","                node = node.select()\n","                #chcek if the node is a terminated one \n","                #action taken -> action of the opponent\n","            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n","            value = self.game.get_opponent_value(value)\n","\n","            # expansion \n","            if not is_terminal: \n","                policy, value = self.model(\n","                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n","                )\n","                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","                legal_actions = self.game.get_legal_actions(node.state)\n","                policy += legal_actions\n","                policy /= np.sum(policy)\n","\n","                #just want to get the float from the value head\n","                value = value.item()\n","\n","                node.expand(policy)\n","                #we remove the simulation part \n","    \n","            # backpropagation \n","            node.backpropagate(value)\n","\n","        # return visit_counts \n","        action_probs = np.zeros(self.game.action_size)\n","        for child in root.children: \n","            action_probs[child.action_taken] = child.visit_count \n","        action_probs /= np.sum(action_probs)\n","        return action_probs\n"]},{"cell_type":"markdown","metadata":{},"source":["# AlphaZero class"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:33:59.895617Z","iopub.status.busy":"2024-02-16T07:33:59.894814Z","iopub.status.idle":"2024-02-16T07:33:59.911364Z","shell.execute_reply":"2024-02-16T07:33:59.910360Z","shell.execute_reply.started":"2024-02-16T07:33:59.895586Z"},"trusted":true},"outputs":[],"source":["import random\n","class AlphaZero: \n","    def __init__(self, model, optimizer, game, args): \n","        self.model = model \n","        self.optimizer = optimizer\n","        self.game = game \n","        self.args = args\n","        self.mcts = MCTS(game, args, model)\n","\n","    def selfPlay(self):\n","        memory = []\n","        player = 1\n","        state = self.game.get_initial_state()\n","        \n","        while True:\n","            neutral_state = self.game.change_perspective(state, player)\n","            action_probs = self.mcts.search(neutral_state)\n","            \n","            memory.append((neutral_state, action_probs, player))\n","            action = np.random.choice(self.game.action_size, p=action_probs)\n","            state = self.game.get_next_state(state, action, player)\n","            value, is_terminal = self.game.get_value_and_terminated(state, action)\n","            \n","            if is_terminal:\n","                returnMemory = []\n","                for hist_neutral_state, hist_action_probs, hist_player in memory:\n","                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n","                    returnMemory.append((\n","                        self.game.get_encoded_state(hist_neutral_state),\n","                        hist_action_probs,\n","                        hist_outcome\n","                    ))\n","                return returnMemory\n","            \n","            player = self.game.get_opponent(player)\n","\n","    def train(self, memory): \n","        random.shuffle(memory)\n","        for batchIdx in range(0, len(memory), self.args['batch_size']): \n","            sample = memory[batchIdx: min(len(memory)-1,batchIdx + self.args['batch_size'])]\n","            state, policy_targets, value_targets = zip(*sample)\n","\n","            state, policy_targets, value_targets = np.array(state), np.array(policy_targets),  np.array(value_targets).reshape(-1,1)\n","            state = torch.tensor(state, dtype = torch.float32)\n","            policy_targets = torch.tensor(policy_targets, dtype = torch.float32)\n","            value_targets = torch.tensor(value_targets, dtype = torch.float32)\n","\n","            out_policy, out_value = self.model(state)\n","            policy_loss = F.cross_entropy(out_policy, policy_targets)\n","            value_loss = F.mse_loss(out_value, value_targets)\n","            loss = policy_loss + value_loss\n","\n","            #minimize the loss by backpropagating \n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","\n","    def learn(self): \n","        for iteration in range(self.args['num_iterations']): \n","            print(\"iteration :\", iteration)\n","            memory = []\n","\n","            self.model.eval()\n","            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']): \n","                print(\"selfPlay_iteration :\", selfPlay_iteration)\n","                memory += self.selfPlay()\n","  \n","            self.model.train()\n","            for epoch in trange(self.args['num_epochs']): \n","                print(\"epoch :\", epoch)\n","                self.train(memory)\n","            \n","            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n","            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["# Test of the Game : look at the generated policies for a given state"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T07:34:32.589064Z","iopub.status.busy":"2024-02-16T07:34:32.588388Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af54717b5c334114b019236cf69db46e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e4e50872dc34ef19b2454b3bd99a982","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be77d21904cb44ce8883421296b03e45","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83db3954e5114716818e4385f106d29f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad61fd6cb6dd41e88d644b4eda07153c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7730afb62b6c4d2f9551cbc0d64ba24b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["connect4 = Connect4()\n","model = ResNet(connect4, 4, 64)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","args = {\n","    'C': 2, \n","    'num_searches': 60, \n","    'num_iterations': 3, \n","    'num_selfPlay_iterations':100, \n","    'num_epochs': 3,\n","    'batch_size': 16\n","}\n","\n","alphaZero = AlphaZero(model, optimizer, connect4, args)\n","alphaZero.learn()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1.]]\n","\n"," [[1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 0. 1. 1. 1. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0.]]]\n","value : -0.11234381049871445 policy : [8.1682134e-01 5.3588249e-04 1.4727749e-03 1.5530065e-01 2.1377509e-02\n"," 3.5948004e-03 8.9707057e-04]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","connect4 = Connect4()\n","\n","state = connect4.get_initial_state()\n","state = connect4.get_next_state(state, 2, 1)\n","state = connect4.get_next_state(state, 6, -1)\n","\n","encoded_state = connect4.get_encoded_state(state)\n","print(encoded_state)\n","\n","tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n","\n","model = ResNet(connect4, 4, 64)\n","model.load_state_dict(torch.load('model_2_<__main__.Connect4 object at 0x7fe2310b78b0>.pt'))\n","model.eval()\n","\n","\n","policy, value = model(tensor_state)\n","value = value.item()\n","policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","\n","print(\"value :\", value, \"policy :\", policy)\n","\n","plt.bar(range(connect4.action_size), policy)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# AlphaZero Version with Dirichlet "]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["class Node:\n","    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n","        self.game = game\n","        self.args = args\n","        self.state = state\n","        self.parent = parent\n","        self.action_taken = action_taken\n","        self.prior = prior\n","        \n","        self.children = []\n","        \n","        self.visit_count = visit_count\n","        self.value_sum = 0\n","        \n","    def is_fully_expanded(self):\n","        return len(self.children) > 0\n","    #SELECTION\n","    def select(self):\n","        best_child = None\n","        best_ucb = -np.inf\n","        \n","        for child in self.children:\n","            ucb = self.get_ucb(child)\n","            if ucb > best_ucb:\n","                best_child = child\n","                best_ucb = ucb\n","                \n","        return best_child\n","\n","    # Compute the ucb score to select the best child \n","    def get_ucb(self, child):\n","        if child.visit_count == 0:\n","            q_value = 0\n","        else:\n","            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n","        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n","    \n","    def expand(self, policy):\n","        for action, prob in enumerate(policy):\n","            if prob > 0:\n","                child_state = self.state.copy()\n","                child_state = self.game.get_next_state(child_state, action, 1)\n","                child_state = self.game.change_perspective(child_state, player=-1)\n","\n","                child = Node(self.game, self.args, child_state, self, action, prob)\n","                self.children.append(child)\n","                \n","        return child\n","\n","    #BACKPROPAGATION \n","    def backpropagate(self, value):\n","        self.value_sum += value\n","        self.visit_count += 1\n","        \n","        value = self.game.get_opponent_value(value)\n","        if self.parent is not None:\n","            self.parent.backpropagate(value)  "]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["\n","class MCTS:\n","    def __init__(self, game, args, model):\n","        self.game = game\n","        self.args = args\n","        self.model = model\n","        \n","    @torch.no_grad()\n","    def search(self, state):\n","        root = Node(self.game, self.args, state, visit_count=1)\n","        # ----------------------------dirichlet--------------------------------------\n","        policy, _ = self.model(\n","            torch.tensor(self.game.get_encoded_state(state)).unsqueeze(0)\n","        )\n","        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n","            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n","        \n","        valid_moves = self.game.get_legal_actions(state)\n","        policy *= valid_moves\n","        policy /= np.sum(policy)\n","        root.expand(policy)\n","        # ----------------------------dirichlet--------------------------------------\n","        for search in range(self.args['num_searches']):\n","            node = root\n","            # selection \n","            \n","            while node.is_fully_expanded():\n","                node = node.select()\n","                #check if the node is a terminated one \n","                #action taken -> action of the opponent\n","                \n","            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n","            value = self.game.get_opponent_value(value)\n","            \n","            # expansion \n","            if not is_terminal:\n","                policy, value = self.model(\n","                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n","                )\n","                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","                valid_moves = self.game.get_legal_actions(node.state)\n","                policy *= valid_moves\n","                policy /= np.sum(policy)\n","\n","                #just want to get the float from the value head\n","                value = value.item()\n","                \n","                node.expand(policy)\n","                #we remove the simulation part \n","                \n","            node.backpropagate(value)    \n","            \n","        # return visit_counts  \n","        action_probs = np.zeros(self.game.action_size)\n","        for child in root.children:\n","            action_probs[child.action_taken] = child.visit_count\n","        action_probs /= np.sum(action_probs)\n","        return action_probs\n","        "]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["import random\n","class AlphaZero: \n","    def __init__(self, model, optimizer, game, args): \n","        self.model = model \n","        self.optimizer = optimizer\n","        self.game = game \n","        self.args = args\n","        self.mcts = MCTS(game, args, model)\n","\n","    def selfPlay(self):\n","        memory = []\n","        player = 1\n","        state = self.game.get_initial_state()\n","        \n","        while True:\n","            neutral_state = self.game.change_perspective(state, player)\n","            action_probs = self.mcts.search(neutral_state)\n","            \n","            memory.append((neutral_state, action_probs, player))\n","            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n","            action = np.random.choice(self.game.action_size, p=action_probs) \n","            state = self.game.get_next_state(state, action, player)\n","            value, is_terminal = self.game.get_value_and_terminated(state, action)\n","            \n","            if is_terminal:\n","                returnMemory = []\n","                for hist_neutral_state, hist_action_probs, hist_player in memory:\n","                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n","                    returnMemory.append((\n","                        self.game.get_encoded_state(hist_neutral_state),\n","                        hist_action_probs,\n","                        hist_outcome\n","                    ))\n","                return returnMemory\n","            \n","            player = self.game.get_opponent(player)\n","\n","    def train(self, memory): \n","        random.shuffle(memory)\n","        for batchIdx in range(0, len(memory), self.args['batch_size']): \n","            sample = memory[batchIdx: min(len(memory)-1,batchIdx + self.args['batch_size'])]\n","            state, policy_targets, value_targets = zip(*sample)\n","\n","            state, policy_targets, value_targets = np.array(state), np.array(policy_targets),  np.array(value_targets).reshape(-1,1)\n","            state = torch.tensor(state, dtype = torch.float32)\n","            policy_targets = torch.tensor(policy_targets, dtype = torch.float32)\n","            value_targets = torch.tensor(value_targets, dtype = torch.float32)\n","\n","            out_policy, out_value = self.model(state)\n","            policy_loss = F.cross_entropy(out_policy, policy_targets)\n","            value_loss = F.mse_loss(out_value, value_targets)\n","            loss = policy_loss + value_loss\n","\n","            #minimize the loss by backpropagating \n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","\n","    def learn(self): \n","        for iteration in range(self.args['num_iterations']): \n","            print(\"iteration :\", iteration)\n","            memory = []\n","\n","            self.model.eval()\n","            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']): \n","                print(\"selfPlay_iteration :\", selfPlay_iteration)\n","                memory += self.selfPlay()\n","  \n","            self.model.train()\n","            for epoch in trange(self.args['num_epochs']): \n","                print(\"epoch :\", epoch)\n","                self.train(memory)\n","            \n","            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n","            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["iteration : 0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb43556b9d0a40b79ccecd1922724411","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["selfPlay_iteration : 0\n","selfPlay_iteration : 1\n","selfPlay_iteration : 2\n","selfPlay_iteration : 3\n","selfPlay_iteration : 4\n","selfPlay_iteration : 5\n","selfPlay_iteration : 6\n","selfPlay_iteration : 7\n","selfPlay_iteration : 8\n","selfPlay_iteration : 9\n","selfPlay_iteration : 10\n","selfPlay_iteration : 11\n","selfPlay_iteration : 12\n","selfPlay_iteration : 13\n","selfPlay_iteration : 14\n","selfPlay_iteration : 15\n","selfPlay_iteration : 16\n","selfPlay_iteration : 17\n","selfPlay_iteration : 18\n","selfPlay_iteration : 19\n","selfPlay_iteration : 20\n","selfPlay_iteration : 21\n","selfPlay_iteration : 22\n","selfPlay_iteration : 23\n","selfPlay_iteration : 24\n","selfPlay_iteration : 25\n","selfPlay_iteration : 26\n","selfPlay_iteration : 27\n","selfPlay_iteration : 28\n","selfPlay_iteration : 29\n","selfPlay_iteration : 30\n","selfPlay_iteration : 31\n","selfPlay_iteration : 32\n","selfPlay_iteration : 33\n","selfPlay_iteration : 34\n","selfPlay_iteration : 35\n","selfPlay_iteration : 36\n","selfPlay_iteration : 37\n","selfPlay_iteration : 38\n","selfPlay_iteration : 39\n","selfPlay_iteration : 40\n","selfPlay_iteration : 41\n","selfPlay_iteration : 42\n","selfPlay_iteration : 43\n","selfPlay_iteration : 44\n","selfPlay_iteration : 45\n","selfPlay_iteration : 46\n","selfPlay_iteration : 47\n","selfPlay_iteration : 48\n","selfPlay_iteration : 49\n","selfPlay_iteration : 50\n","selfPlay_iteration : 51\n","selfPlay_iteration : 52\n","selfPlay_iteration : 53\n","selfPlay_iteration : 54\n","selfPlay_iteration : 55\n","selfPlay_iteration : 56\n","selfPlay_iteration : 57\n","selfPlay_iteration : 58\n","selfPlay_iteration : 59\n","selfPlay_iteration : 60\n","selfPlay_iteration : 61\n","selfPlay_iteration : 62\n","selfPlay_iteration : 63\n","selfPlay_iteration : 64\n","selfPlay_iteration : 65\n","selfPlay_iteration : 66\n","selfPlay_iteration : 67\n","selfPlay_iteration : 68\n","selfPlay_iteration : 69\n","selfPlay_iteration : 70\n","selfPlay_iteration : 71\n","selfPlay_iteration : 72\n","selfPlay_iteration : 73\n","selfPlay_iteration : 74\n","selfPlay_iteration : 75\n","selfPlay_iteration : 76\n","selfPlay_iteration : 77\n","selfPlay_iteration : 78\n","selfPlay_iteration : 79\n","selfPlay_iteration : 80\n","selfPlay_iteration : 81\n","selfPlay_iteration : 82\n","selfPlay_iteration : 83\n","selfPlay_iteration : 84\n","selfPlay_iteration : 85\n","selfPlay_iteration : 86\n","selfPlay_iteration : 87\n","selfPlay_iteration : 88\n","selfPlay_iteration : 89\n","selfPlay_iteration : 90\n","selfPlay_iteration : 91\n","selfPlay_iteration : 92\n","selfPlay_iteration : 93\n","selfPlay_iteration : 94\n","selfPlay_iteration : 95\n","selfPlay_iteration : 96\n","selfPlay_iteration : 97\n","selfPlay_iteration : 98\n","selfPlay_iteration : 99\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5c2fe39fff242fbadc035d48d4a9eb3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch : 0\n","epoch : 1\n","epoch : 2\n","iteration : 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40724f66906e4aeea9c0054328c67b7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["selfPlay_iteration : 0\n","selfPlay_iteration : 1\n","selfPlay_iteration : 2\n","selfPlay_iteration : 3\n","selfPlay_iteration : 4\n","selfPlay_iteration : 5\n","selfPlay_iteration : 6\n","selfPlay_iteration : 7\n","selfPlay_iteration : 8\n","selfPlay_iteration : 9\n","selfPlay_iteration : 10\n","selfPlay_iteration : 11\n","selfPlay_iteration : 12\n","selfPlay_iteration : 13\n","selfPlay_iteration : 14\n","selfPlay_iteration : 15\n","selfPlay_iteration : 16\n","selfPlay_iteration : 17\n","selfPlay_iteration : 18\n","selfPlay_iteration : 19\n","selfPlay_iteration : 20\n","selfPlay_iteration : 21\n","selfPlay_iteration : 22\n","selfPlay_iteration : 23\n","selfPlay_iteration : 24\n","selfPlay_iteration : 25\n","selfPlay_iteration : 26\n","selfPlay_iteration : 27\n","selfPlay_iteration : 28\n","selfPlay_iteration : 29\n","selfPlay_iteration : 30\n","selfPlay_iteration : 31\n","selfPlay_iteration : 32\n","selfPlay_iteration : 33\n","selfPlay_iteration : 34\n","selfPlay_iteration : 35\n","selfPlay_iteration : 36\n","selfPlay_iteration : 37\n","selfPlay_iteration : 38\n","selfPlay_iteration : 39\n","selfPlay_iteration : 40\n","selfPlay_iteration : 41\n","selfPlay_iteration : 42\n","selfPlay_iteration : 43\n","selfPlay_iteration : 44\n","selfPlay_iteration : 45\n","selfPlay_iteration : 46\n","selfPlay_iteration : 47\n","selfPlay_iteration : 48\n","selfPlay_iteration : 49\n","selfPlay_iteration : 50\n","selfPlay_iteration : 51\n","selfPlay_iteration : 52\n","selfPlay_iteration : 53\n","selfPlay_iteration : 54\n","selfPlay_iteration : 55\n","selfPlay_iteration : 56\n","selfPlay_iteration : 57\n","selfPlay_iteration : 58\n","selfPlay_iteration : 59\n","selfPlay_iteration : 60\n","selfPlay_iteration : 61\n","selfPlay_iteration : 62\n","selfPlay_iteration : 63\n","selfPlay_iteration : 64\n","selfPlay_iteration : 65\n","selfPlay_iteration : 66\n","selfPlay_iteration : 67\n","selfPlay_iteration : 68\n","selfPlay_iteration : 69\n","selfPlay_iteration : 70\n","selfPlay_iteration : 71\n","selfPlay_iteration : 72\n","selfPlay_iteration : 73\n","selfPlay_iteration : 74\n","selfPlay_iteration : 75\n","selfPlay_iteration : 76\n","selfPlay_iteration : 77\n","selfPlay_iteration : 78\n","selfPlay_iteration : 79\n","selfPlay_iteration : 80\n","selfPlay_iteration : 81\n","selfPlay_iteration : 82\n","selfPlay_iteration : 83\n","selfPlay_iteration : 84\n","selfPlay_iteration : 85\n","selfPlay_iteration : 86\n","selfPlay_iteration : 87\n","selfPlay_iteration : 88\n","selfPlay_iteration : 89\n","selfPlay_iteration : 90\n","selfPlay_iteration : 91\n","selfPlay_iteration : 92\n","selfPlay_iteration : 93\n","selfPlay_iteration : 94\n","selfPlay_iteration : 95\n","selfPlay_iteration : 96\n","selfPlay_iteration : 97\n","selfPlay_iteration : 98\n","selfPlay_iteration : 99\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d68803d02f0d411fac890661a9628b7a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch : 0\n","epoch : 1\n","epoch : 2\n","iteration : 2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2756775e67e45daa37f8c2765dd09c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["selfPlay_iteration : 0\n","selfPlay_iteration : 1\n","selfPlay_iteration : 2\n","selfPlay_iteration : 3\n","selfPlay_iteration : 4\n","selfPlay_iteration : 5\n","selfPlay_iteration : 6\n","selfPlay_iteration : 7\n","selfPlay_iteration : 8\n","selfPlay_iteration : 9\n","selfPlay_iteration : 10\n","selfPlay_iteration : 11\n","selfPlay_iteration : 12\n","selfPlay_iteration : 13\n","selfPlay_iteration : 14\n","selfPlay_iteration : 15\n","selfPlay_iteration : 16\n","selfPlay_iteration : 17\n","selfPlay_iteration : 18\n","selfPlay_iteration : 19\n","selfPlay_iteration : 20\n","selfPlay_iteration : 21\n","selfPlay_iteration : 22\n","selfPlay_iteration : 23\n","selfPlay_iteration : 24\n","selfPlay_iteration : 25\n","selfPlay_iteration : 26\n","selfPlay_iteration : 27\n","selfPlay_iteration : 28\n","selfPlay_iteration : 29\n","selfPlay_iteration : 30\n","selfPlay_iteration : 31\n","selfPlay_iteration : 32\n","selfPlay_iteration : 33\n","selfPlay_iteration : 34\n","selfPlay_iteration : 35\n","selfPlay_iteration : 36\n","selfPlay_iteration : 37\n","selfPlay_iteration : 38\n","selfPlay_iteration : 39\n","selfPlay_iteration : 40\n","selfPlay_iteration : 41\n","selfPlay_iteration : 42\n","selfPlay_iteration : 43\n","selfPlay_iteration : 44\n","selfPlay_iteration : 45\n","selfPlay_iteration : 46\n","selfPlay_iteration : 47\n","selfPlay_iteration : 48\n","selfPlay_iteration : 49\n","selfPlay_iteration : 50\n","selfPlay_iteration : 51\n","selfPlay_iteration : 52\n","selfPlay_iteration : 53\n","selfPlay_iteration : 54\n","selfPlay_iteration : 55\n","selfPlay_iteration : 56\n","selfPlay_iteration : 57\n","selfPlay_iteration : 58\n","selfPlay_iteration : 59\n","selfPlay_iteration : 60\n","selfPlay_iteration : 61\n","selfPlay_iteration : 62\n","selfPlay_iteration : 63\n","selfPlay_iteration : 64\n","selfPlay_iteration : 65\n","selfPlay_iteration : 66\n","selfPlay_iteration : 67\n","selfPlay_iteration : 68\n","selfPlay_iteration : 69\n","selfPlay_iteration : 70\n","selfPlay_iteration : 71\n","selfPlay_iteration : 72\n","selfPlay_iteration : 73\n","selfPlay_iteration : 74\n","selfPlay_iteration : 75\n","selfPlay_iteration : 76\n","selfPlay_iteration : 77\n","selfPlay_iteration : 78\n","selfPlay_iteration : 79\n","selfPlay_iteration : 80\n","selfPlay_iteration : 81\n","selfPlay_iteration : 82\n","selfPlay_iteration : 83\n","selfPlay_iteration : 84\n","selfPlay_iteration : 85\n","selfPlay_iteration : 86\n","selfPlay_iteration : 87\n","selfPlay_iteration : 88\n","selfPlay_iteration : 89\n","selfPlay_iteration : 90\n","selfPlay_iteration : 91\n","selfPlay_iteration : 92\n","selfPlay_iteration : 93\n","selfPlay_iteration : 94\n","selfPlay_iteration : 95\n","selfPlay_iteration : 96\n","selfPlay_iteration : 97\n","selfPlay_iteration : 98\n","selfPlay_iteration : 99\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eaba7fcaf4364983a4e506e608ead729","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch : 0\n","epoch : 1\n","epoch : 2\n"]}],"source":["connect4 = Connect4()\n","model = ResNet(connect4, 4, 64)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","args = {\n","    'C': 2,\n","    'num_searches': 60, \n","    'num_iterations': 3, \n","    'num_selfPlay_iterations':100, \n","    'num_epochs': 3,\n","    'batch_size': 16,\n","    'temperature': 1.25,\n","    'dirichlet_epsilon': 0.25,\n","    'dirichlet_alpha': 0.3\n","}\n","\n","\n","\n","alphaZero = AlphaZero(model, optimizer, connect4, args)\n","alphaZero.learn()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1.]]\n","\n"," [[1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 0. 1. 1. 1. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0.]]]\n","value : 0.247343972325325 policy : [0.2172347  0.27530435 0.07425594 0.14856645 0.08141904 0.11927931\n"," 0.08394005]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","connect4 = Connect4()\n","\n","state = connect4.get_initial_state()\n","state = connect4.get_next_state(state, 2, 1)\n","state = connect4.get_next_state(state, 6, -1)\n","\n","encoded_state = connect4.get_encoded_state(state)\n","print(encoded_state)\n","\n","tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n","\n","model = ResNet(connect4, 4, 64)\n","model.load_state_dict(torch.load('model_2.pt'))\n","model.eval()\n","\n","\n","policy, value = model(tensor_state)\n","value = value.item()\n","policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","\n","print(\"value :\", value, \"policy :\", policy)\n","\n","plt.bar(range(connect4.action_size), policy)\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3.10.6","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"c3a5ae1ae8efed8e3cf296aadad5ee3571cbe0979bef69c7518f24f99ae72373"}}},"nbformat":4,"nbformat_minor":4}
